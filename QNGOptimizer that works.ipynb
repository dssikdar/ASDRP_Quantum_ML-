{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6076cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2021-07-23 22:55:25,647: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Importing standard Qiskit libraries\n",
    "from qiskit import QuantumCircuit, transpile, Aer, IBMQ\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from ibm_quantum_widgets import *\n",
    "\n",
    "# Loading your IBM Quantum account(s)\n",
    "provider = IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c86ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018-2021 Xanadu Quantum Technologies Inc.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Quantum natural gradient optimizer\"\"\"\n",
    "# pylint: disable=too-many-branches\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.utils import _flatten, unflatten\n",
    "from pennylane.optimize.gradient_descent import GradientDescentOptimizer\n",
    "\n",
    "\n",
    "class QNGOptimizer(GradientDescentOptimizer):\n",
    "    r\"\"\"Optimizer with adaptive learning rate, via calculation\n",
    "    of the diagonal or block-diagonal approximation to the Fubini-Study metric tensor.\n",
    "    A quantum generalization of natural gradient descent.\n",
    "\n",
    "    The QNG optimizer uses a step- and parameter-dependent learning rate,\n",
    "    with the learning rate dependent on the pseudo-inverse\n",
    "    of the Fubini-Study metric tensor :math:`g`:\n",
    "\n",
    "    .. math::\n",
    "        x^{(t+1)} = x^{(t)} - \\eta g(f(x^{(t)}))^{-1} \\nabla f(x^{(t)}),\n",
    "\n",
    "    where :math:`f(x^{(t)}) = \\langle 0 | U(x^{(t)})^\\dagger \\hat{B} U(x^{(t)}) | 0 \\rangle`\n",
    "    is an expectation value of some observable measured on the variational\n",
    "    quantum circuit :math:`U(x^{(t)})`.\n",
    "\n",
    "    Consider a quantum node represented by the variational quantum circuit\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        U(\\mathbf{\\theta}) = W(\\theta_{i+1}, \\dots, \\theta_{N})X(\\theta_{i})\n",
    "        V(\\theta_1, \\dots, \\theta_{i-1}),\n",
    "\n",
    "    where all parametrized gates can be written of the form :math:`X(\\theta_{i}) = e^{i\\theta_i K_i}`.\n",
    "    That is, the gate :math:`K_i` is the *generator* of the parametrized operation :math:`X(\\theta_i)`\n",
    "    corresponding to the :math:`i`-th parameter.\n",
    "\n",
    "    For each parametric layer :math:`\\ell` in the variational quantum circuit\n",
    "    containing :math:`n` parameters, the :math:`n\\times n` block-diagonal submatrix\n",
    "    of the Fubini-Study tensor :math:`g_{ij}^{(\\ell)}` is calculated directly on the\n",
    "    quantum device in a single evaluation:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        g_{ij}^{(\\ell)} = \\langle \\psi_\\ell | K_i K_j | \\psi_\\ell \\rangle\n",
    "        - \\langle \\psi_\\ell | K_i | \\psi_\\ell\\rangle\n",
    "        \\langle \\psi_\\ell |K_j | \\psi_\\ell\\rangle\n",
    "\n",
    "    where :math:`|\\psi_\\ell\\rangle =  V(\\theta_1, \\dots, \\theta_{i-1})|0\\rangle`\n",
    "    (that is, :math:`|\\psi_\\ell\\rangle` is the quantum state prior to the application\n",
    "    of parameterized layer :math:`\\ell`).\n",
    "\n",
    "    Combining the quantum natural gradient optimizer with the analytic parameter-shift\n",
    "    rule to optimize a variational circuit with :math:`d` parameters and :math:`L` layers,\n",
    "    a total of :math:`2d+L` quantum evaluations are required per optimization step.\n",
    "\n",
    "    For more details, see:\n",
    "\n",
    "        James Stokes, Josh Izaac, Nathan Killoran, Giuseppe Carleo.\n",
    "        \"Quantum Natural Gradient.\" `arXiv:1909.02108 <https://arxiv.org/abs/1909.02108>`_, 2019.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        The QNG optimizer supports single QNodes or :class:`~.ExpvalCost` objects as objective functions.\n",
    "        Alternatively, the metric tensor can directly be provided to the :func:`step` method of the optimizer,\n",
    "        using the ``metric_tensor_fn`` argument.\n",
    "\n",
    "        For the following cases, providing metric_tensor_fn may be useful:\n",
    "\n",
    "        * For hybrid classical-quantum models, the \"mixed geometry\" of the model\n",
    "          makes it unclear which metric should be used for which parameter.\n",
    "          For example, parameters of quantum nodes are better suited to\n",
    "          one metric (such as the QNG), whereas others (e.g., parameters of classical nodes)\n",
    "          are likely better suited to another metric.\n",
    "\n",
    "        * For multi-QNode models, we don't know what geometry is appropriate\n",
    "          if a parameter is shared amongst several QNodes.\n",
    "\n",
    "        If the objective function is VQE/VQE-like, i.e., a function of a group\n",
    "        of QNodes that share an ansatz, there are two ways to use the optimizer:\n",
    "\n",
    "        * Realize the objective function as an :class:`~.ExpvalCost` object, which has\n",
    "          a ``metric_tensor`` method.\n",
    "\n",
    "        * Manually provide the ``metric_tensor_fn`` corresponding to the metric tensor of\n",
    "          of the QNode(s) involved in the objective function.\n",
    "\n",
    "    **Examples:**\n",
    "\n",
    "    For VQE/VQE-like problems, the objective function for the optimizer can be\n",
    "    realized as an ExpvalCost object.\n",
    "\n",
    "    >>> dev = qml.device(\"default.qubit\", wires=1)\n",
    "    >>> def circuit(params, wires=0):\n",
    "    ...     qml.RX(params[0], wires=wires)\n",
    "    ...     qml.RY(params[1], wires=wires)\n",
    "    >>> coeffs = [1, 1]\n",
    "    >>> obs = [qml.PauliX(0), qml.PauliZ(0)]\n",
    "    >>> H = qml.Hamiltonian(coeffs, obs)\n",
    "    >>> cost_fn = qml.ExpvalCost(circuit, H, dev)\n",
    "\n",
    "    Once constructed, the cost function can be passed directly to the\n",
    "    optimizer's ``step`` function:\n",
    "\n",
    "    >>> eta = 0.01\n",
    "    >>> init_params = np.array([0.011, 0.012])\n",
    "    >>> opt = qml.QNGOptimizer(eta)\n",
    "    >>> theta_new = opt.step(cost_fn, init_params)\n",
    "    >>> print(theta_new)\n",
    "    [0.011445239214543481, -0.027519522461477233]\n",
    "\n",
    "    Alternatively, the same objective function can be used for the optimizer\n",
    "    by manually providing the ``metric_tensor_fn``.\n",
    "\n",
    "    >>> qnodes = qml.map(circuit, obs, dev, 'expval')\n",
    "    >>> cost_fn = qml.dot(coeffs, qnodes)\n",
    "    >>> eta = 0.01\n",
    "    >>> init_params = np.array([0.011, 0.012])\n",
    "    >>> opt = qml.QNGOptimizer(eta)\n",
    "    >>> theta_new = opt.step(cost_fn, init_params, metric_tensor_fn=qnodes.qnodes[0].metric_tensor)\n",
    "    >>> print(theta_new)\n",
    "    [0.011445239214543481, -0.027519522461477233]\n",
    "\n",
    "    .. seealso::\n",
    "\n",
    "        See the :ref:`quantum natural gradient example <quantum_natural_gradient>`\n",
    "        for more details on Fubini-Study metric tensor and this optimization class.\n",
    "\n",
    "    Args:\n",
    "        stepsize (float): the user-defined hyperparameter :math:`\\eta`\n",
    "        diag_approx (bool): If ``True``, forces a diagonal approximation\n",
    "            where the calculated metric tensor only contains diagonal\n",
    "            elements :math:`G_{ii}`. In some cases, this may reduce the\n",
    "            time taken per optimization step.\n",
    "        lam (float): metric tensor regularization :math:`G_{ij}+\\lambda I`\n",
    "            to be applied at each optimization step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stepsize=0.01, diag_approx=False, lam=0):\n",
    "        super().__init__(stepsize)\n",
    "        self.diag_approx = diag_approx\n",
    "        self.metric_tensor = None\n",
    "        self.lam = lam\n",
    "\n",
    "    def step_and_cost(self, qnode, x, recompute_tensor=True, metric_tensor_fn=None):\n",
    "        \"\"\"Update the parameter array :math:`x` with one step of the optimizer and return the\n",
    "        corresponding objective function value prior to the step.\n",
    "\n",
    "        Args:\n",
    "            qnode (QNode): the QNode for optimization\n",
    "            x (array): NumPy array containing the current values of the variables to be updated\n",
    "            recompute_tensor (bool): Whether or not the metric tensor should\n",
    "                be recomputed. If not, the metric tensor from the previous\n",
    "                optimization step is used.\n",
    "            metric_tensor_fn (function): Optional metric tensor function\n",
    "                with respect to the variables ``x``.\n",
    "                If ``None``, the metric tensor function is computed automatically.\n",
    "\n",
    "        Returns:\n",
    "            tuple: the new variable values :math:`x^{(t+1)}` and the objective function output\n",
    "            prior to the step\n",
    "        \"\"\"\n",
    "        # pylint: disable=arguments-differ\n",
    "        if not isinstance(qnode, (qml.QNode, qml.ExpvalCost)) and metric_tensor_fn is None:\n",
    "            raise ValueError(\n",
    "                \"The objective function must either be encoded as a single QNode or \"\n",
    "                \"an ExpvalCost object for the natural gradient to be automatically computed. \"\n",
    "                \"Otherwise, metric_tensor_fn must be explicitly provided to the optimizer.\"\n",
    "            )\n",
    "\n",
    "        if recompute_tensor or self.metric_tensor is None:\n",
    "            if metric_tensor_fn is None:\n",
    "                # pseudo-inverse metric tensor\n",
    "                self.metric_tensor = qml.metric_tensor(qnode, diag_approx=self.diag_approx)(x)\n",
    "            else:\n",
    "                self.metric_tensor = metric_tensor_fn(x)\n",
    "            self.metric_tensor += self.lam * np.identity(self.metric_tensor.shape[0])\n",
    "\n",
    "        # The QNGOptimizer.step does not permit passing an external gradient function.\n",
    "        # Autograd will always calculate the gradient and `forward` will never be `None`.\n",
    "        g, forward = self.compute_grad(qnode, (x,), dict())\n",
    "        x_out = self.apply_grad(g, x)\n",
    "        return x_out, forward\n",
    "\n",
    "\n",
    "    # pylint: disable=arguments-differ\n",
    "    def step(self, qnode, x, recompute_tensor=True, metric_tensor_fn=None):\n",
    "        \"\"\"Update the parameter array :math:`x` with one step of the optimizer.\n",
    "\n",
    "        Args:\n",
    "            qnode (QNode): the QNode for optimization\n",
    "            x (array): NumPy array containing the current values of the variables to be updated\n",
    "            recompute_tensor (bool): Whether or not the metric tensor should\n",
    "                be recomputed. If not, the metric tensor from the previous\n",
    "                optimization step is used.\n",
    "            metric_tensor_fn (function): Optional metric tensor function\n",
    "                with respect to the variables ``x``.\n",
    "                If ``None``, the metric tensor function is computed automatically.\n",
    "\n",
    "        Returns:\n",
    "            array: the new variable values :math:`x^{(t+1)}`\n",
    "        \"\"\"\n",
    "        x_out, _ = self.step_and_cost(\n",
    "            qnode, x, recompute_tensor=recompute_tensor, metric_tensor_fn=metric_tensor_fn\n",
    "        )\n",
    "        return x_out\n",
    "\n",
    "\n",
    "    def apply_grad(self, grad, x):\n",
    "        r\"\"\"Update the parameter array :math:`x` for a single optimization step. Flattens and\n",
    "        unflattens the inputs to maintain nested iterables as the parameters of the optimization.\n",
    "\n",
    "        Args:\n",
    "            grad (array): The gradient of the objective\n",
    "                function at point :math:`x^{(t)}`: :math:`\\nabla f(x^{(t)})`\n",
    "            x (array): the current value of the variables :math:`x^{(t)}`\n",
    "\n",
    "        Returns:\n",
    "            array: the new values :math:`x^{(t+1)}`\n",
    "        \"\"\"\n",
    "        grad_flat = np.array(list(_flatten(grad)))\n",
    "        x_flat = np.array(list(_flatten(x)))\n",
    "        x_new_flat = x_flat - self._stepsize * np.linalg.solve(self.metric_tensor, grad_flat)\n",
    "        return unflatten(x_new_flat, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3502e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "def circuit(params, wires=4):\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.Hadamard(wires=1)\n",
    "    qml.Hadamard(wires=2)\n",
    "    qml.Hadamard(wires=3)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    qml.RX(params[0], wires=0)\n",
    "    qml.RY(params[1], wires=0)\n",
    "    qml.RY(np.pi, wires=0)\n",
    "    qml.RY(np.pi, wires=1)\n",
    "    qml.RY(np.pi, wires=2)\n",
    "    qml.RY(np.pi, wires=3)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.CNOT(wires=[2,3])\n",
    "    qml.U3(params[2], params[3], params[4], wires=0)\n",
    "    qml.U3(params[5], params[6], params[7], wires=1)\n",
    "    qml.U3(params[8], params[9], params[10], wires=2)\n",
    "    qml.U3(params[11], params[12], params[13], wires=3)\n",
    "    qml.CRot(params[14], params[15], params[16], wires=[0,1])\n",
    "    qml.CRot(params[17], params[18], params[19], wires=[2,3])\n",
    "coeffs = [1, 1]\n",
    "obs = [qml.PauliZ(0), qml.PauliZ(0)]\n",
    "H = qml.Hamiltonian(coeffs, obs)\n",
    "cost_fn = qml.ExpvalCost(circuit, H, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81c301fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14159265 3.14159265 1.57079633 1.57079633 1.65079633 1.57079633\n",
      " 1.56996299 1.57079633 1.57079633 1.57079633 1.57079633 1.56902856\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.56829633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633] \n",
      "\n",
      "[3.14247416 3.14159265 1.57079633 1.57079633 1.73105301 1.57079633\n",
      " 1.56996299 1.57079633 1.57079633 1.57079633 1.57079633 1.56590356\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.56329633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633] \n",
      "\n",
      "[3.14496684 3.14159265 1.57079633 1.57079633 1.81209141 1.57079633\n",
      " 1.56996299 1.57079633 1.57079633 1.57079633 1.57079633 1.57257023\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.56829633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633] \n",
      "\n",
      "[3.14270121 3.14159265 1.57079633 1.57079633 1.89447821 1.57079633\n",
      " 1.56996299 1.57079633 1.57079633 1.57079633 1.57079633 1.56507023\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.56829633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633] \n",
      "\n",
      "[3.16755473 3.14159265 1.57079633 1.57079633 1.9788601  1.57079633\n",
      " 1.56996299 1.57079633 1.57079633 1.57079633 1.57079633 1.56507023\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.56829633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633 1.57079633\n",
      " 1.57079633 1.57079633 1.57079633 1.57079633] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "eta = 0.01\n",
    "init_params = np.array([np.pi, np.pi,\n",
    "                        np.pi/2, np.pi/2, np.pi/2, #U3 One\n",
    "                        np.pi/2, np.pi/2, np.pi/2, #U3 Two\n",
    "                        np.pi/2, np.pi/2, np.pi/2, #U3 Three\n",
    "                        np.pi/2, np.pi/2, np.pi/2, #U3 Four\n",
    "                        np.pi/2, np.pi/2, np.pi/2,\n",
    "                        np.pi/2, np.pi/2, np.pi/2,\n",
    "                        np.pi/2, np.pi/2, np.pi/2,\n",
    "                        np.pi/2, np.pi/2, np.pi/2, \n",
    "                        np.pi/2, np.pi/2])\n",
    "opt = qml.QNGOptimizer(eta)\n",
    "\n",
    "for i in range(5):\n",
    "    init_params = opt.step(cost_fn, init_params)\n",
    "    print(init_params, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408854c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
